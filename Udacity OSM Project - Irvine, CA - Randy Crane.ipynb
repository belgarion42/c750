{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Project Outline:\n",
    "\n",
    "1) Introduction - DONE\n",
    "2) Import map data - DONE\n",
    "3) Create sample of of map data - DONE\n",
    "4) Basic overview of data\n",
    "5) List/explain 2 or 3 problems found in data (eg. abbreviated street names, incorrect postal codes, ???)\n",
    "6) Correct problem 1\n",
    "7) Correct problem 2\n",
    "8) Correct problem 3 (if applicable)\n",
    "9) Export data as csv file\n",
    "10) Import csv file into sql\n",
    "11) Compute overview of staistics of file:\n",
    "    a) size of the file\n",
    "    b) number of unique users\n",
    "    c) number of nodes and ways\n",
    "    d) number of chosen type of nodes, like cafes, shops etc.\n",
    "    e) Top 10 contributing users\n",
    "    f) Most popular cuisines?\n",
    "12) Conclusion\n",
    "    a) Ideas for improving the data set more\n",
    "    b) discussion about the benefits as well as some anticipated problems in implementing the improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>\n",
    "\n",
    "In this project I will be exploring OpenStreetMap data for Irvine, California. I chose this map data because Irvine is my current city of residence. I am already pretty familiar with the area, which will potentially help me recognize some of the bad data in the set. At the same time, I'm curious about some aspects of my city and I will use this data set to glean some new insights about it.\n",
    "\n",
    "The data consists of XML elements called \"nodes\" (points of interest) and \"ways\" (linear features and area boundaries). Each element can have one or more tags associated with it. These tags provide more details and information about the element.  Additional information about the data structure can be found here: https://wiki.openstreetmap.org/wiki/OSM_XML\n",
    "\n",
    "I will first explore the raw XML data using Python and audit tags that are appear to have errors, and tags that I'm interested in analyzing in more detail. Due to the scope of this project, I will not be cleaning every error I find, but will focus on two or three to meet the requirements of the project. After identifying and cleaning the problem areas, I will export the data to CSV files, then import it into a SQLite database. Finally, I will query the database to gain greater insights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Map Area</h1>\n",
    "\n",
    "On OpenStreetMap.org, the area I selected to include as much of Irvine I could without too much data from other cities is bounded within the following coordinates:\n",
    "\n",
    "Longitude: -117.8792, -117.7281\n",
    "Latitude: 33.7301, 33.6135\n",
    "\n",
    "The map can be found here: https://www.openstreetmap.org/search?query=Irvine%2C%20CA#map=12/33.7299/-117.8232. The underlying data was downloaded using the Overpass API, at this link: https://overpass-api.de/api/map?bbox=-117.8792,33.6135,-117.7281,33.7301.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\randy'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Documents\\\\School - WGU\\\\Term 4\\\\C750\\\\Project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"D:\\Documents\\School - WGU\\Term 4\\C750\\Project\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Exploration and Cleaning</h1>\n",
    "\n",
    "Using the 'OSM_sampling.py' script provided by Udacity, I will create a sample file of every 100th element from the original file map data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "no element found: line 3, column 2 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\randy\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3343\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-6-3dec3e6d6311>\"\u001b[0m, line \u001b[0;32m26\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    for i, element in enumerate(get_element(OSM_FILE)):\n",
      "  File \u001b[0;32m\"<ipython-input-6-3dec3e6d6311>\"\u001b[0m, line \u001b[0;32m16\u001b[0m, in \u001b[0;35mget_element\u001b[0m\n    for event, elem in context:\n",
      "  File \u001b[0;32m\"C:\\Users\\randy\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[0m, line \u001b[0;32m1227\u001b[0m, in \u001b[0;35miterator\u001b[0m\n    root = pullparser._close_and_return_root()\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\randy\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[1;36m, line \u001b[1;32m1274\u001b[1;36m, in \u001b[1;35m_close_and_return_root\u001b[1;36m\u001b[0m\n\u001b[1;33m    root = self._parser.close()\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32munknown\u001b[0m\n\u001b[1;31mParseError\u001b[0m\u001b[1;31m:\u001b[0m no element found: line 3, column 2\n"
     ]
    }
   ],
   "source": [
    "#Import osm file and create sample dataset\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"map.osm\"\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 100 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "            \n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write(b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write(b'<osm>\\n  ')\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "    output.write(b'</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will parse the dataset to count the unique element types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', )):\n",
    "        if elem.tag not in tags:\n",
    "            tags[elem.tag] = 1\n",
    "        else:\n",
    "            tags[elem.tag] += 1\n",
    "    return tags\n",
    "\n",
    "def test():\n",
    "\n",
    "    tags = count_tags('map.osm')\n",
    "    pprint.pprint(tags)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I explored these files and discovered the following problems with the data:\n",
    "\n",
    "<ul>\n",
    "<li>Abbreviated street types</li>\n",
    "<li>Incomplete post codes</li>\n",
    "<li>Inconsistent handling of \"type\" data</li>\n",
    "<li>Inconsistent handling of shop data</li>\n",
    "<li>Redundant data values</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
